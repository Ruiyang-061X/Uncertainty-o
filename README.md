<p align="center">
    <img src=".asset/logo.png" width="20%"> <br>
</p>

# ğŸ” Uncertainty-o

[Ruiyang Zhang](https://ruiyang-061x.github.io/), [Hu Zhang](https://huzhangcs.github.io/), [Hao Fei](https://haofei.vip/), [Zehdong Zheng*](https://www.zdzheng.xyz/)

**[Website](https://Uncertainty-o.github.io/)** | **[Paper]()** | **[Code](https://github.com/Ruiyang-061X/Uncertainty-o)**


## âš¡ Overview

<p align="center">
    <img src=".asset/overview.png" width="80%"> <br>
</p>

## ğŸ”¥ News

- 2025.3.11: ğŸ£ Source code of [Uncertainty-o](https://github.com/Ruiyang-061X/Uncertainty-o) is released!

## ğŸ“‹ Contents
- [âœï¸ Method](#%EF%B8%8F-method)
- [ğŸ› ï¸ Install](#%EF%B8%8F-install)
- [ğŸ’» Dependency](#-dependency)
- [ğŸ“š Data Preparation](#-data-preparation)
- [ğŸ“ˆ Run](#-run)
- [ğŸ„ Examples](#-examples)
- [âŒ¨ï¸ Code Structure](#%EF%B8%8F-code-structure)
- [âœ¨ Acknowledgement](#-acknowledgement)
- [ğŸ“ Citation](#-citation)

## âœï¸ Method

<p align="center">
    <img src=".asset/method.png" width="80%"> <br>
</p>

**Pipeline of Our Uncertainty-o.** Given a multimodal prompt and large multimodal models, we perform multimodal prompt perturbation to generate diverse responses. Due to the inherent epistemic uncertainty of these models under perturbation, varied responses are typically obtained. To quantify this uncertainty, we apply semantic clustering on the collected responses and compute their entropy. Specifically, responses are grouped into semantically similar clusters, and the entropy across these clusters is calculated as the final uncertainty measure. Higher entropy indicates greater variability in responses, suggesting lower confidence, while lower entropy reflects higher consistency and thus higher confidence.

## ğŸ› ï¸ Install

- Create conda environment.

```
conda create -n Uncertainty-o python=3.11;

conda activate Uncertainty-o;
```

- Install dependency.

```
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121;

pip install transformers datasets flash-attn accelerate timm numpy sentencepiece protobuf qwen_vl_utils;
```

(Tested on NVIDIA H100, NVIDIA A100)

## ğŸ’» Dependency

Refer to [Dependency.md](doc/Dependency.md).


## ğŸ“š Data Preparation

Refer to [Data.md](doc/Data.md).

## ğŸ“ˆ Run

- For Comprehension Hallucination Detection, Hallucination Detection for Closed-Source LMMs, Hallucination Detection for Safety-Critic Tasks

```
bash run/comprehension_hallucination_detection.sh;
```

- For Generation Hallucination Detection

```
bash run/generation_hallucination_detection.sh;
```

- For Hallucination Mitigation

```
bash run/hallucination_mitigation.sh;
```

- For Uncertainty-Aware Chain-of-Thought

```
bash run/uncertainty_aware_cot.sh;
```

## ğŸ„ Examples

- Uncertainty-o successfully detects both comprehension and generation hallucination:

<p align="center">
    <img src=".asset/qualitative_case.png" width="100%"> <br>
</p>

## âŒ¨ï¸ Code Structure

- Code strucuture of this repostory is as follow:

```
â”œâ”€â”€ Uncertainty-o/ 
â”‚   â”œâ”€â”€ .asset/
â”‚   â”œâ”€â”€ args/                       # Args parser
â”‚   â”œâ”€â”€ benchmark/
â”‚   â”‚   â”œâ”€â”€ comprehension/          # Benchmark for comprehension task
â”‚   â”‚   â”œâ”€â”€ generation/             # Benchmark for generation task
â”‚   â”œâ”€â”€ dependency/                 # Downstream source code for LMMs
â”‚   â”œâ”€â”€ factory/                    # Builder for benchmarks, models
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ Qwen.py                 # LLM class
â”‚   â”œâ”€â”€ metric/                     # Metric for hallucination detection
â”‚   â”œâ”€â”€ mllm/
â”‚   â”‚   â”œâ”€â”€ comprehension/          # LMM for comprehension task
â”‚   â”‚   â”œâ”€â”€ generation/             # LMM for generation task
â”‚   â”œâ”€â”€ perturbation/               # Multimodal prompt perturbation
â”‚   â”œâ”€â”€ run/                        # Experiment scripts
â”‚   â”œâ”€â”€ uncertainty/                # Multimodal semantic uncertainty
â”‚   â”œâ”€â”€ util/
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ hallucination_detection.py  
â”‚   â”œâ”€â”€ hallucination_mitigation.py 
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ uncertainty_aware_cot.py    
```

## âœ¨ Acknowledgement

- [AnyGPT](https://github.com/OpenMOSS/AnyGPT), [OneLLM](https://github.com/csuhan/OneLLM), [InternVL](https://github.com/OpenGVLab/InternVL), [PointLLM](https://github.com/OpenRobotLab/PointLLM): Thanks a lot for those foundamental efforts!
- [semantic_uncertainty](https://github.com/jlko/semantic_uncertainty): We are inspired a lot by this work!
- [VL-Uncertainty](https://github.com/Ruiyang-061X/VL-Uncertainty): We build our codebase based on this work!


## ğŸ“ Citation

If you find our work useful for your research and application, please cite using this BibTeX:

```bibtex
@article{zhang2025uncertainty,
  title={Uncertainty-o: One Model-agnostic Framework for Unveiling Epistemic Uncertainty in Large Multimodal Models},
  author={Zhang, Ruiyang and Zhang, Hu and Hao Fei, and Zheng, Zhedong},
  year={2025}
}
```
